//! Falsification Protocol Tests for ttop v2.1.0
//!
//! These tests attempt to BREAK the implementation using edge cases,
//! stress tests, and logic traps as specified in the falsification protocol.

use std::path::PathBuf;

// Import modules under test
use ttop::analyzers::{
    DiskIoAnalyzer, IoWorkloadType, LargeFileDetector, StorageAnalyzer, SwapAnalyzer,
    ThrashingSeverity, ZramStats,
};
use ttop::ring_buffer::{handle_counter_wrap, RingBuffer};

// =============================================================================
// ðŸ”´ VECTOR 1: Ring Buffer & SIMD
// =============================================================================

mod ring_buffer_attacks {
    use super::*;

    /// Attack 1.1: The "Max Int" Cliff
    /// Inject u64::MAX - 1, followed by 5. Does rate calculation show overflow?
    #[test]
    fn attack_max_int_cliff_counter_wrap() {
        // Simulate counter at u64::MAX - 1, then wrapping to 5
        let prev = u64::MAX - 1;
        let curr = 5u64;

        let delta = handle_counter_wrap(prev, curr);

        // Expected: (u64::MAX - (u64::MAX - 1) + 5 + 1) = 7
        // The counter wrapped from MAX-1 to 5, so delta should be 7
        assert_eq!(delta, 7, "Counter wrap calculation failed!");

        // Now test with the ring buffer's rate calculation
        let mut rb: RingBuffer<u64> = RingBuffer::new(10);

        // Push the delta values
        rb.push(delta);
        rb.push(10);
        rb.push(15);

        // Rate should not be astronomical
        let rate = rb.rate_per_sec(1.0);
        assert!(
            rate < 1_000_000.0,
            "Rate calculation shows overflow! Got: {}",
            rate
        );
    }

    /// Attack 1.1b: Edge case - exactly at MAX
    #[test]
    fn attack_exact_max_wrap() {
        let prev = u64::MAX;
        let curr = 0u64;

        let delta = handle_counter_wrap(prev, curr);
        // Should be 1 (one increment to wrap)
        assert_eq!(delta, 1, "Exact MAX wrap failed!");
    }

    /// Attack 1.1c: No wrap scenario (sanity check)
    #[test]
    fn attack_no_wrap_sanity() {
        let prev = 100u64;
        let curr = 150u64;

        let delta = handle_counter_wrap(prev, curr);
        assert_eq!(delta, 50, "Normal delta failed!");
    }

    /// Attack 1.3: The Flatline
    /// Fill buffer with identical values. Does std dev divide by zero?
    #[test]
    fn attack_flatline_identical_values() {
        let mut rb: RingBuffer<f64> = RingBuffer::new(100);

        // Fill with identical values
        for _ in 0..100 {
            rb.push(42.0);
        }

        // These should NOT panic or return NaN/Infinity
        let mean = rb.mean();
        let min = rb.min();
        let max = rb.max();

        assert!(!mean.is_nan(), "Mean is NaN for identical values!");
        assert!(!mean.is_infinite(), "Mean is Infinite!");
        assert!(
            (mean - 42.0).abs() < 0.001,
            "Mean should be 42.0, got {}",
            mean
        );
        assert!((min - 42.0).abs() < 0.001, "Min should be 42.0");
        assert!((max - 42.0).abs() < 0.001, "Max should be 42.0");

        // Rate calculation should also be safe
        let rate = rb.rate_per_sec(1.0);
        assert!(!rate.is_nan(), "Rate is NaN!");
        assert!(!rate.is_infinite(), "Rate is Infinite!");
    }

    /// Attack 1.3b: Empty buffer edge case
    #[test]
    fn attack_empty_buffer_stats() {
        let rb: RingBuffer<f64> = RingBuffer::new(10);

        // These should return safe defaults, not panic
        let mean = rb.mean();
        let min = rb.min();
        let max = rb.max();
        let rate = rb.rate_per_sec(1.0);

        // Check they don't panic and return reasonable defaults
        assert!(
            mean == 0.0 || mean.is_nan(),
            "Empty mean should be 0 or NaN"
        );
        assert!(!rate.is_infinite(), "Empty rate should not be infinite");
    }
}

// =============================================================================
// ðŸ”´ VECTOR 2: Swap Analyzer & Denning's Model
// =============================================================================

mod swap_analyzer_attacks {
    use super::*;

    /// Attack 2.1: The "Cold Swap" Paradox
    /// High swap usage (storage) but ZERO activity (I/O) and ZERO PSI.
    /// Should return ThrashingSeverity::None, NOT Severe/Moderate.
    #[test]
    fn attack_cold_swap_paradox() {
        let analyzer = SwapAnalyzer::new();

        // With no activity (no collect() calls building history),
        // swap_rate should be 0, fault_rate should be 0, PSI should be 0
        let swap_rate = analyzer.swap_rate_per_sec();
        let fault_rate = analyzer.major_fault_rate_per_sec();
        let psi = analyzer.psi();

        assert!(swap_rate < 0.001, "Swap rate should be ~0");
        assert!(fault_rate < 0.001, "Fault rate should be ~0");
        assert!(psi.some_avg10 < 0.001, "PSI should be ~0");

        // CRITICAL: With zero activity, thrashing should be NONE
        let severity = analyzer.detect_thrashing();
        assert_eq!(
            severity,
            ThrashingSeverity::None,
            "Cold swap should NOT report thrashing! Got: {:?}",
            severity
        );
    }

    /// Attack 2.2: The Zero-ZRAM Division
    /// Mock ZRAM returning 0 for compressed size. Does ratio panic or return NaN?
    #[test]
    fn attack_zero_zram_division() {
        let stats = ZramStats {
            orig_data_size: 1000,
            compr_data_size: 0, // ZERO compressed size!
            mem_used_total: 0,
            mem_limit: 0,
            max_used_pages: 0,
            same_pages: 0,
            pages_compacted: 0,
            huge_pages: 0,
            comp_algorithm: String::new(),
            device: "zram0".to_string(),
        };

        let ratio = stats.compression_ratio();

        // Should NOT panic, should NOT be NaN
        assert!(!ratio.is_nan(), "ZRAM ratio is NaN on zero compressed!");
        assert!(
            !ratio.is_infinite(),
            "ZRAM ratio is Infinite on zero compressed!"
        );

        // With zero compressed, ratio defaults to 1.0 (as per implementation)
        assert!(
            (ratio - 1.0).abs() < 0.001,
            "ZRAM ratio should be 1.0, got {}",
            ratio
        );
    }

    /// Attack 2.2b: Both zero - completely empty ZRAM
    #[test]
    fn attack_empty_zram() {
        let stats = ZramStats::default();

        let ratio = stats.compression_ratio();
        let savings = stats.space_savings_percent();

        assert!(!ratio.is_nan(), "Empty ZRAM ratio is NaN!");
        assert!(!savings.is_nan(), "Empty ZRAM savings is NaN!");
        assert!(!stats.is_active(), "Empty ZRAM should not be active!");
    }

    /// Attack 2.3: PSI Flicker (boundary testing)
    /// Values oscillating around threshold (9.9% vs 10.1%)
    #[test]
    fn attack_psi_boundary_stability() {
        // Test exact boundaries
        // PSI thresholds from spec: >10% = Mild, >25% = Moderate, >50% = Severe

        // This is a static test since we can't inject PSI values directly,
        // but we can verify the threshold logic is correct
        let analyzer = SwapAnalyzer::new();

        // Default analyzer has PSI = 0, should be None
        assert_eq!(analyzer.detect_thrashing(), ThrashingSeverity::None);

        // NOTE: To properly test PSI flickering, we'd need to mock /proc/pressure/memory
        // This test documents the expected behavior at boundaries
    }
}

// =============================================================================
// ðŸ”´ VECTOR 3: Disk I/O & Little's Law
// =============================================================================

mod disk_io_attacks {
    use super::*;
    use ttop::analyzers::disk_io::{
        classify_workload, estimate_latency_ms, estimate_p50_latency_ms, estimate_p99_latency_ms,
    };

    /// Attack 3.1: The "Stuck I/O" Scenario
    /// Queue Depth = 50, IOPS = 0. Little's Law implies division by zero!
    #[test]
    fn attack_stuck_io_division_by_zero() {
        let queue_depth = 50.0;
        let iops = 0.0; // Drive hanging!

        let latency = estimate_latency_ms(queue_depth, iops);

        // Should NOT panic, should NOT be Infinity or NaN
        assert!(!latency.is_nan(), "Stuck I/O latency is NaN!");
        assert!(!latency.is_infinite(), "Stuck I/O latency is Infinite!");

        // Implementation should return 0.0 for zero IOPS
        assert_eq!(latency, 0.0, "Stuck I/O latency should be 0, got {}", latency);
    }

    /// Attack 3.1b: Very low IOPS (near-zero)
    #[test]
    fn attack_near_zero_iops() {
        let queue_depth = 50.0;
        let iops = 0.5; // Below threshold

        let latency = estimate_latency_ms(queue_depth, iops);

        // Implementation treats iops < 1.0 as effectively zero
        assert_eq!(latency, 0.0, "Near-zero IOPS should return 0 latency");
    }

    /// Attack 3.1c: Normal case sanity check
    #[test]
    fn attack_normal_littles_law() {
        let queue_depth = 10.0;
        let iops = 1000.0;

        // W = L / Î» = 10 / 1000 = 0.01 seconds = 10 ms
        let latency = estimate_latency_ms(queue_depth, iops);
        assert!(
            (latency - 10.0).abs() < 0.001,
            "Normal latency should be 10ms, got {}",
            latency
        );
    }

    /// Attack 3.2: The "Sequential" Trap
    /// P99 assumes exponential distribution. Sequential workloads should NOT
    /// show massively inflated P99.
    #[test]
    fn attack_sequential_p99_validity() {
        // For sequential workload, P99 = avg * 4.605 is technically wrong
        // but this tests that the calculation at least doesn't produce
        // absurd values

        let avg_latency = 1.0; // 1ms average
        let p99 = estimate_p99_latency_ms(avg_latency);
        let p50 = estimate_p50_latency_ms(avg_latency);

        // P99 should be ~4.6ms (for exponential)
        assert!(
            (p99 - 4.605).abs() < 0.1,
            "P99 calculation wrong: {}",
            p99
        );

        // P50 should be ~0.69ms
        assert!(
            (p50 - 0.693).abs() < 0.1,
            "P50 calculation wrong: {}",
            p50
        );

        // Key insight: For sequential, the p99/avg ratio is mathematically
        // correct for the model, but semantically may overestimate.
        // This is a KNOWN LIMITATION, not a bug.
    }

    /// Attack 3.3: Workload Jitter
    /// Alternating between 4KB random and 1GB sequential
    #[test]
    fn attack_workload_jitter_classification() {
        // 4KB random: high IOPS, low throughput
        let random_iops = 10000.0;
        let random_throughput = 40.0; // 40 MB/s at 4KB per IO

        let random_class = classify_workload(random_iops, random_throughput);
        assert_eq!(
            random_class,
            IoWorkloadType::Random,
            "4KB random should be Random, got {:?}",
            random_class
        );

        // 1GB sequential: low IOPS, high throughput
        let seq_iops = 10.0; // 10 1GB writes
        let seq_throughput = 10000.0; // 10 GB/s

        let seq_class = classify_workload(seq_iops, seq_throughput);
        assert_eq!(
            seq_class,
            IoWorkloadType::Sequential,
            "1GB sequential should be Sequential, got {:?}",
            seq_class
        );

        // Mixed: moderate IOPS, moderate throughput
        let mixed_iops = 500.0;
        let mixed_throughput = 50.0;

        let mixed_class = classify_workload(mixed_iops, mixed_throughput);
        // Could be Mixed or Sequential depending on ratio
        assert!(
            mixed_class != IoWorkloadType::Idle,
            "Active workload should not be Idle"
        );
    }

    /// Attack 3.3b: Rapid workload type changes
    #[test]
    fn attack_rapid_workload_changes() {
        let mut analyzer = DiskIoAnalyzer::new();

        // Multiple collects shouldn't cause issues
        for _ in 0..10 {
            analyzer.collect();
        }

        // Should not panic, should return reasonable values
        let workload = analyzer.overall_workload();
        let _read = analyzer.total_read_throughput();
        let _write = analyzer.total_write_throughput();
        let _iops = analyzer.total_iops();

        // With no real data, should be Idle
        assert_eq!(workload, IoWorkloadType::Idle);
    }
}

// =============================================================================
// ðŸ”´ VECTOR 4: Storage & Z-Score Anomalies
// =============================================================================

mod storage_attacks {
    use super::*;

    /// Attack 4.1: The "Uniform World" Crash
    /// Every file is exactly 1024 bytes. MAD will be 0.
    /// New file of 1025 bytes - does Z-score divide by zero?
    #[test]
    fn attack_uniform_world_mad_zero() {
        let mut detector = LargeFileDetector::with_capacity(100, 50, 3.5);

        // Fill with identical file sizes (MAD = 0)
        for i in 0..50 {
            detector.on_file_created(PathBuf::from(format!("/tmp/file{}", i)), 1024);
        }

        // Now check if 1025 bytes triggers divide by zero
        let z_score = detector.calculate_z_score(1025);

        assert!(!z_score.is_nan(), "Uniform world Z-score is NaN!");
        assert!(
            !z_score.is_infinite(),
            "Uniform world Z-score is Infinite!"
        );

        // With MAD=0, the fallback logic should kick in
        // 1025 is NOT > median * 10 (1024 * 10 = 10240), so z_score should be 0
        assert!(
            z_score < 10.0,
            "Small deviation should not be anomalous, got z={}",
            z_score
        );
    }

    /// Attack 4.1b: Uniform world with LARGE anomaly
    #[test]
    fn attack_uniform_world_large_anomaly() {
        let mut detector = LargeFileDetector::with_capacity(100, 50, 3.5);

        // Fill with identical file sizes
        for i in 0..50 {
            detector.on_file_created(PathBuf::from(format!("/tmp/file{}", i)), 1000);
        }

        // 100KB file (100x larger than median)
        let z_score = detector.calculate_z_score(100_000);

        assert!(!z_score.is_nan(), "Large anomaly Z-score is NaN!");

        // With MAD=0, files > median*10 return z_score = 10.0
        assert!(
            z_score >= 10.0,
            "100x file should be detected as anomaly, got z={}",
            z_score
        );
    }

    /// Attack 4.2: Stress test detector with rapid creation
    #[test]
    fn attack_rapid_file_creation() {
        let mut detector = LargeFileDetector::with_capacity(1000, 100, 3.5);

        // Simulate 1000 rapid file creations
        for i in 0..1000 {
            let size = (i % 100 + 1) * 1024; // 1KB to 100KB
            let anomaly =
                detector.on_file_created(PathBuf::from(format!("/tmp/rapid{}", i)), size as u64);

            // Most should NOT be anomalies (they're in normal range)
            if let Some(a) = anomaly {
                // Only very large files should be anomalies after history builds up
                assert!(
                    a.size > 50 * 1024,
                    "Small file incorrectly flagged as anomaly"
                );
            }
        }
    }

    /// Attack 4.3: False Positive - Slow growing file
    /// Does a file that grows over time trigger false positives?
    #[test]
    fn attack_slow_growing_file() {
        let mut detector = LargeFileDetector::with_capacity(100, 50, 3.5);

        // Create baseline: files from 1KB to 10KB
        for i in 1..=50 {
            detector.on_file_created(
                PathBuf::from(format!("/tmp/baseline{}", i)),
                i * 1024,
            );
        }

        // Now simulate a file that "grows" - each creation is a new snapshot
        // This should NOT trigger anomaly for gradual growth
        let mut anomaly_count = 0;
        for size_kb in [11, 12, 13, 14, 15, 20, 25, 30] {
            if let Some(_) = detector.on_file_created(
                PathBuf::from("/tmp/growing_file"),
                size_kb * 1024,
            ) {
                anomaly_count += 1;
            }
        }

        // Gradual growth within 3x of median should not trigger many anomalies
        assert!(
            anomaly_count <= 2,
            "Too many false positives for gradual growth: {}",
            anomaly_count
        );
    }

    /// Attack 4.3b: Truly anomalous file
    #[test]
    fn attack_true_anomaly_detection() {
        let mut detector = LargeFileDetector::with_capacity(100, 50, 3.5);

        // Create baseline: files from 1KB to 10KB
        for i in 1..=50 {
            detector.on_file_created(
                PathBuf::from(format!("/tmp/normal{}", i)),
                i * 1024,
            );
        }

        // 10GB file should DEFINITELY be an anomaly
        let result = detector.on_file_created(
            PathBuf::from("/tmp/huge_anomaly"),
            10 * 1024 * 1024 * 1024,
        );

        assert!(
            result.is_some(),
            "10GB file should be detected as anomaly!"
        );
        let anomaly = result.expect("checked above");
        assert!(
            anomaly.z_score > 3.5,
            "Anomaly z_score should exceed threshold"
        );
    }
}

// =============================================================================
// INTEGRATION TESTS
// =============================================================================

mod integration_attacks {
    use super::*;

    /// Verify analyzer integration doesn't panic under normal operation
    #[test]
    fn attack_analyzer_integration_stability() {
        let mut swap = SwapAnalyzer::new();
        let mut disk = DiskIoAnalyzer::new();
        let mut storage = StorageAnalyzer::new();

        // Multiple collect cycles
        for _ in 0..5 {
            swap.collect();
            disk.collect();
            storage.collect();
        }

        // All accessors should work
        let _ = swap.detect_thrashing();
        let _ = swap.zram_compression_ratio();
        let _ = swap.psi();
        let _ = disk.overall_workload();
        let _ = disk.total_iops();
        let _ = storage.mounts();
    }
}

// =============================================================================
// ðŸ”´ ADDITIONAL EDGE CASE ATTACKS
// =============================================================================

mod edge_case_attacks {
    use super::*;

    /// Attack: Negative latency (impossible but let's see)
    #[test]
    fn attack_negative_queue_depth() {
        use ttop::analyzers::disk_io::estimate_latency_ms;
        
        // Negative queue depth is impossible but...
        let latency = estimate_latency_ms(-10.0, 1000.0);
        
        // Should produce negative or handle gracefully
        assert!(latency <= 0.0 || !latency.is_nan(), "Negative QD handled");
    }

    /// Attack: Maximum throughput values
    #[test]
    fn attack_extreme_throughput() {
        use ttop::analyzers::disk_io::classify_workload;
        
        // Petabytes per second (impossible but test bounds)
        let class = classify_workload(1.0, 1_000_000_000.0);
        assert_eq!(class, IoWorkloadType::Sequential);
    }

    /// Attack: Ring buffer at exact capacity boundary
    #[test]
    fn attack_ring_buffer_boundary() {
        let mut rb: RingBuffer<u64> = RingBuffer::new(5);
        
        // Fill exactly to capacity
        for i in 0..5 {
            rb.push(i);
        }
        
        // Push one more (should wrap)
        rb.push(100);
        
        // Verify it didn't corrupt
        let sum: u64 = rb.iter().sum();
        assert!(sum > 0, "Ring buffer corrupted at boundary");
    }

    /// Attack: PSI with exactly boundary values
    #[test]
    fn attack_psi_exact_boundaries() {
        // The thresholds are: >10 (Mild), >25 (Moderate), >50 (Severe)
        // Test with EXACTLY those values
        
        let analyzer = SwapAnalyzer::new();
        // We can't inject PSI values, but we verify the detection logic
        assert_eq!(analyzer.detect_thrashing(), ThrashingSeverity::None);
    }

    /// Attack: Z-score with very small MAD
    #[test]
    fn attack_tiny_mad() {
        let mut detector = LargeFileDetector::with_capacity(100, 50, 3.5);
        
        // Very similar file sizes - tiny MAD
        for i in 0..50 {
            let size = 1000 + (i % 3); // 1000, 1001, 1002 cycling
            detector.on_file_created(
                PathBuf::from(format!("/tmp/similar{}", i)),
                size as u64,
            );
        }
        
        // Small deviation - should NOT overflow
        let z = detector.calculate_z_score(1010);
        assert!(!z.is_nan() && !z.is_infinite(), "Tiny MAD caused overflow");
    }

    /// Attack: Workload classifier edge case - exact threshold
    #[test]
    fn attack_workload_exact_threshold() {
        use ttop::analyzers::disk_io::classify_workload;
        
        // EXACTLY at idle threshold: iops=10, throughput=1
        let class = classify_workload(10.0, 1.0);
        // Should NOT be Idle (threshold is <10 AND <1)
        assert_ne!(class, IoWorkloadType::Idle, "Exact threshold should not be Idle");
    }
}
